import nltk
import pandas as pd
import torch
import torch.nn.functional as F
from sentence_transformers import SentenceTransformer
from transformers import pipeline
from datetime import datetime
# from gpt4all import GPT4All

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# print(device)

# gpt_model = GPT4All("orca-mini-3b-gguf2-q4_0.gguf")
embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)

# Description generated by GPT for each key factor
political_instability = "Political instability refers to a state of uncertainty and turmoil within a country's political system. It often involves frequent changes in leadership, government policies, or a lack of effective governance. Factors contributing to political instability can include conflicts, corruption, economic crises, social unrest, and power struggles among different political groups. Political instability can have adverse effects on a nation's economy, security, and overall well-being, making it challenging to achieve stability and progress."
geopolitical_factors = "Geopolitical factors are elements of global politics that influence the relationships and actions of countries on the international stage. These factors can include geographical location, natural resources, military power, economic strength, and cultural, historical, and strategic considerations. Geopolitical factors play a crucial role in shaping international relations, alliances, conflicts, and foreign policy decisions of nations. They can also impact trade, security, and the distribution of power in the world."
currency_fluctuations = "Currency fluctuations, also known as exchange rate fluctuations, refer to the changes in the value of one currency relative to another in the foreign exchange market. These fluctuations occur due to various factors such as changes in economic conditions, interest rates, inflation rates, political stability, and market sentiment. Currency values can appreciate (strengthen) or depreciate (weaken) over time, impacting international trade, investment, and the cost of imported goods and services. Currency fluctuations can have significant economic implications for both individuals and businesses engaged in cross-border transactions."
investment_demand = "Investment demand refers to the desire and willingness of businesses and individuals to invest in capital goods and assets such as machinery, equipment, buildings, or financial securities like stocks and bonds. It is a component of aggregate demand in macroeconomics. Factors influencing investment demand include interest rates, business expectations, economic conditions, and government policies. When investment demand is high, it typically indicates economic optimism and can lead to increased economic growth and job creation. Conversely, low investment demand may result in slower economic growth."
supply_demand = "Supply and demand are fundamental concepts in economics. Supply refers to the quantity of a good or service that producers are willing and able to offer for sale in the market at different prices. The supply typically increases as prices rise and decreases as prices fall. Demand  represents the quantity of a good or service that consumers are willing and able to purchase at different prices. Demand generally rises as prices fall and falls as prices rise. The interaction between supply and demand in a market determines the equilibrium price and quantity. When supply and demand are in balance, the market reaches an equilibrium where the quantity supplied equals the quantity demanded, and the prevailing price is the equilibrium price. Changes in supply and demand can lead to shifts in prices and quantities in the market, which is a central concept in understanding how markets work and how prices are determined."
industrial_demand = "Industrial demand refers to the need for goods and services by businesses and industries to support their production and operational activities. This type of demand is driven by factors such as the business cycle, technological advancements, and market conditions. Industrial demand can encompass a wide range of products, including raw materials, machinery, equipment, energy, and specialized services. It is an essential component of overall economic activity and can fluctuate based on the health of the industrial sector and broader economic trends."
natural_disasters = "Natural disasters are sudden and severe events caused by natural forces, often resulting in widespread damage, destruction, and loss of life. These events can include earthquakes, hurricanes, tornadoes, floods, wildfires, tsunamis, volcanic eruptions, and more. Natural disasters can have devastating impacts on communities, ecosystems, and infrastructure, and they are typically beyond human control. Preparedness, mitigation, and response efforts are crucial in reducing the negative consequences of natural disasters."

# Use sentence embeddings to generate description embedings
# political instability
embedding_political_instability = embedding_model.encode(nltk.tokenize.sent_tokenize(political_instability, language='english'))
torch_embedding_political_instability = torch.from_numpy(embedding_political_instability).to(device)
mean_embedding_political_instability = torch.mean(torch_embedding_political_instability, dim=0)
# geopolitical factors
embedding_geopolitical_factors = embedding_model.encode(nltk.tokenize.sent_tokenize(geopolitical_factors, language='english'))
torch_embedding_geopolitical_factors = torch.from_numpy(embedding_geopolitical_factors).to(device)
mean_embedding_geopolitical_factors = torch.mean(torch_embedding_geopolitical_factors, dim=0)
# currency fluctuations
embedding_currency_fluctuations = embedding_model.encode(nltk.tokenize.sent_tokenize(currency_fluctuations, language='english'))
torch_embedding_currency_fluctuations = torch.from_numpy(embedding_currency_fluctuations).to(device)
mean_embedding_currency_fluctuations = torch.mean(torch_embedding_currency_fluctuations, dim=0)
# investment demand
embedding_investment_demand = embedding_model.encode(nltk.tokenize.sent_tokenize(investment_demand, language='english'))
torch_embedding_investment_demand = torch.from_numpy(embedding_investment_demand).to(device)
mean_embedding_investment_demand = torch.mean(torch_embedding_investment_demand, dim=0)
# supply demand
embedding_supply_demand = embedding_model.encode(nltk.tokenize.sent_tokenize(supply_demand, language='english'))
torch_embedding_supply_demand = torch.from_numpy(embedding_supply_demand).to(device)
mean_embedding_supply_demand = torch.mean(torch_embedding_supply_demand, dim=0)
# industrial demand
embedding_industrial_demand = embedding_model.encode(nltk.tokenize.sent_tokenize(industrial_demand, language='english'))
torch_embedding_industrial_demand = torch.from_numpy(embedding_industrial_demand).to(device)
mean_embedding_industrial_demand = torch.mean(torch_embedding_industrial_demand, dim=0)
# natural disasters
embedding_natural_disasters = embedding_model.encode(nltk.tokenize.sent_tokenize(natural_disasters, language='english'))
torch_embedding_natural_disasters = torch.from_numpy(embedding_natural_disasters).to(device)
mean_embedding_natural_disasters = torch.mean(torch_embedding_natural_disasters, dim=0)

mean_embedding_category = torch.stack(
    [mean_embedding_political_instability, mean_embedding_geopolitical_factors, mean_embedding_currency_fluctuations, mean_embedding_investment_demand,
    mean_embedding_supply_demand, mean_embedding_industrial_demand, mean_embedding_natural_disasters]).to(device)


def feature_extract(df_all, curr_date):
    df = df_all[df_all[0] == curr_date]
    df = df.sample(n=min(50, len(df)), random_state=42)
    # print(len(df))

    category_cosine_similarities_list = []
    category_sentiment_score_list = []

    for i in range(len(df)):
        row = df.iloc[i]
        
        # Summarize the text news
        # with gpt_model.chat_session():
        #     summarize_test = gpt_model.generate(prompt='Summarize this article: ' + pd_articles[3][0], temp=0)
        # print(summarize_test)
        # sentences = nltk.tokenize.sent_tokenize(summarize_test, language='english')
        sentences = nltk.tokenize.sent_tokenize(row[2], language='english')
        embedding_news = embedding_model.encode(sentences)

        torch_embedding_news = torch.from_numpy(embedding_news).to(device)
        mean_embedding_news = torch.mean(torch_embedding_news, dim=0, keepdim=True)

        # Compute the cosine similarity between each news and each key factor
        category_cosine_similarities = F.cosine_similarity(mean_embedding_news, mean_embedding_category, dim=1)
        category_cosine_similarities_list.append(category_cosine_similarities)
        # print(category_cosine_similarities)

        distilled_student_sentiment_classifier = pipeline(
            model="lxyuan/distilbert-base-multilingual-cased-sentiments-student", 
            top_k=None, padding=True, truncation=True, max_length=512, add_special_tokens=True,
            device=device
        )

        # Sentiment analysis of each news
        sentiments_list = []
        for sentence in sentences:
            sentiment = distilled_student_sentiment_classifier(sentence)[0]
            sentiments_list.append([dict["score"] for dict in sentiment])
        sentence_sentiments = torch.tensor(sentiments_list).to(device)
        news_sentiments = torch.mean(sentence_sentiments, dim=0)
        # print(news_sentiments)

        # Combining the sentiment analysis and the cosine similarity
        sentiment_score = torch.dot(news_sentiments, torch.tensor([1.0, 0.0, -1.0]).to(device))
        category_sentiment_score = sentiment_score * category_cosine_similarities
        category_sentiment_score_list.append(category_sentiment_score)
        # print(category_sentiment_score)

    day_category_cosine_similarities = torch.stack(category_cosine_similarities_list).to(device)
    day_category_sentiment_score = torch.stack(category_sentiment_score_list).to(device)

    # Calculate the maximum values for each row and select the top 25 rows from the original tensor to find the most impactful news
    row_max_values, _ = torch.max(day_category_cosine_similarities, dim=1)
    _, top_indices = torch.topk(row_max_values, k=min(25, day_category_cosine_similarities.shape[0]))

    top_day_category_cosine_similarities = day_category_cosine_similarities[top_indices]
    top_day_category_sentiment_score = day_category_sentiment_score[top_indices]

    mean_day_category_cosine_similarities = torch.mean(day_category_cosine_similarities, dim=0)
    mean_day_category_sentiment_score = torch.mean(day_category_sentiment_score, dim=0)
    top_mean_day_category_cosine_similarities = torch.mean(top_day_category_cosine_similarities, dim=0)
    top_mean_day_category_sentiment_score = torch.mean(top_day_category_sentiment_score, dim=0)

    # print(mean_day_category_cosine_similarities)
    # print(mean_day_category_sentiment_score)

    return (
        mean_day_category_cosine_similarities, mean_day_category_sentiment_score, 
        top_mean_day_category_cosine_similarities, top_mean_day_category_sentiment_score
    )

columns = ["Date", "x1", "x2", "x3", "x4", "x5", "x6", "x7", "Close"]

df_all = pd.read_excel('data/news.xlsx', engine='openpyxl', header=None)  
df_dow_jones_raw = pd.read_csv('data/dow_jones_raw.csv')
df_dow_jones_sentiment = pd.read_csv('data/dow_jones_sentiment.csv')
df_dow_jones_raw_all = pd.DataFrame(columns=columns)
df_dow_jones_sentiment_all = pd.DataFrame(columns=columns)
df_dow_jones_raw_top = pd.DataFrame(columns=columns)
df_dow_jones_sentiment_top = pd.DataFrame(columns=columns)

for i in range(len(df_dow_jones_raw)):
    print(f"current index: {i}")
    
    row = df_dow_jones_raw.iloc[i]
    curr_date = row['Date']
    close_price = row['Close']

    date_obj = datetime.strptime(curr_date, "%m/%d/%Y")
    formatted_date = date_obj.strftime("%-d-%-m-%Y")
    # print(formatted_date)

    # Obtain four distinct embeddings for the key factors for each day
    mean_cos_sim, mean_sentiment, top_mean_cos_sim, top_mean_sentiment = feature_extract(df_all, formatted_date)
    
    new_row = mean_cos_sim.tolist()
    new_row.insert(0, curr_date)
    new_row.append(close_price)
    df_dow_jones_raw_all.loc[len(df_dow_jones_raw_all)] = new_row
    
    new_row = mean_sentiment.tolist()
    new_row.insert(0, curr_date)
    new_row.append(close_price)
    df_dow_jones_sentiment_all.loc[len(df_dow_jones_sentiment_all)] = new_row

    new_row = top_mean_cos_sim.tolist()
    new_row.insert(0, curr_date)
    new_row.append(close_price)
    df_dow_jones_raw_top.loc[len(df_dow_jones_raw_top)] = new_row
    
    new_row = top_mean_sentiment.tolist()
    new_row.insert(0, curr_date)
    new_row.append(close_price)
    df_dow_jones_sentiment_top.loc[len(df_dow_jones_sentiment_top)] = new_row

    df_dow_jones_raw_all.to_csv('data/dow_jones_raw_all.csv', index=False)
    df_dow_jones_sentiment_all.to_csv('data/dow_jones_sentiment_all.csv', index=False)
    df_dow_jones_raw_top.to_csv('data/dow_jones_raw_top.csv', index=False)
    df_dow_jones_sentiment_top.to_csv('data/dow_jones_sentiment_top.csv', index=False)